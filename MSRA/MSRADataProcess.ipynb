{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T07:06:40.157211Z",
     "start_time": "2019-05-18T07:06:39.905526Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-37d4a7ea374d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tfenv\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tfenv\\lib\\site-packages\\pandas\\core\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrays\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_eng_float_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m from pandas.core.index import (Index, CategoricalIndex, Int64Index,\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tfenv\\lib\\site-packages\\pandas\\core\\groupby\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGroupBy\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m from pandas.core.groupby.generic import (  # noqa: F401\n\u001b[0;32m      3\u001b[0m     SeriesGroupBy, DataFrameGroupBy, PanelGroupBy)\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGrouper\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tfenv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroupby\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlibgroupby\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunction\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'compat'"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "#HULK_Z\n",
    "import codecs\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-18T07:02:51.279Z"
    }
   },
   "outputs": [],
   "source": [
    "input_data = codecs.open('train.txt','r','utf-8')\n",
    "output_data = codecs.open('wordtag.txt','w','utf-8')\n",
    "for line in input_data.readlines():\n",
    "    #line=re.split('[，。；！：？、‘’“”]/[o]'.decode('utf-8'),line.strip())\n",
    "    line = line.strip().split()\n",
    "        \n",
    "    if len(line)==0:\n",
    "        continue\n",
    "    for word in line:\n",
    "        word = word.split('/')\n",
    "        if word[1]!='o':\n",
    "            if len(word[0])==1:\n",
    "                output_data.write(word[0]+\"/B_\"+word[1]+\" \")\n",
    "            elif len(word[0])==2:\n",
    "                output_data.write(word[0][0]+\"/B_\"+word[1]+\" \")\n",
    "                output_data.write(word[0][1]+\"/E_\"+word[1]+\" \")\n",
    "            else:\n",
    "                output_data.write(word[0][0]+\"/B_\"+word[1]+\" \")\n",
    "                for j in word[0][1:len(word[0])-1]:\n",
    "                    output_data.write(j+\"/M_\"+word[1]+\" \")\n",
    "                output_data.write(word[0][-1]+\"/E_\"+word[1]+\" \")\n",
    "        else:\n",
    "            for j in word[0]:\n",
    "                output_data.write(j+\"/o\"+\" \")\n",
    "    output_data.write('\\n')\n",
    "        \n",
    "            \n",
    "input_data.close()\n",
    "output_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-18T07:02:52.002Z"
    }
   },
   "outputs": [],
   "source": [
    "datas = list()\n",
    "labels = list()\n",
    "linedata=list()\n",
    "linelabel=list()\n",
    "\n",
    "tag2id = {'' :0,\n",
    "'B_ns' :1,\n",
    "'B_nr' :2,\n",
    "'B_nt' :3,\n",
    "'M_nt' :4,\n",
    "'M_nr' :5,\n",
    "'M_ns' :6,\n",
    "'E_nt' :7,\n",
    "'E_nr' :8,\n",
    "'E_ns' :9,\n",
    "'o': 0}\n",
    "\n",
    "id2tag = {0:'' ,\n",
    "1:'B_ns' ,\n",
    "2:'B_nr' ,\n",
    "3:'B_nt' ,\n",
    "4:'M_nt' ,\n",
    "5:'M_nr' ,\n",
    "6:'M_ns' ,\n",
    "7:'E_nt' ,\n",
    "8:'E_nr' ,\n",
    "9:'E_ns' ,\n",
    "10: 'o'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-18T07:02:52.454Z"
    }
   },
   "outputs": [],
   "source": [
    "input_data = codecs.open('wordtag.txt','r','utf-8')\n",
    "for line in input_data.readlines():\n",
    "    line=re.split('[，。；！：？、‘’“”]/[o]',line.strip())\n",
    "    for sen in line:\n",
    "        sen = sen.strip().split()\n",
    "        if len(sen)==0:\n",
    "            continue\n",
    "        linedata=[]\n",
    "        linelabel=[]\n",
    "        num_not_o=0\n",
    "        for word in sen:\n",
    "            word = word.split('/')\n",
    "            linedata.append(word[0])\n",
    "            linelabel.append(tag2id[word[1]])\n",
    "\n",
    "            if word[1]!='o':\n",
    "                num_not_o+=1\n",
    "        if num_not_o!=0:\n",
    "            datas.append(linedata)\n",
    "            labels.append(linelabel)\n",
    "            \n",
    "input_data.close()    \n",
    "print(len(datas))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-18T07:02:52.831Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatten(x): # 展平\n",
    "    result = []\n",
    "    for el in x:\n",
    "        if isinstance(x, collections.Iterable) and not isinstance(el, str):\n",
    "            result.extend(flatten(el))\n",
    "        else:\n",
    "            result.append(el)\n",
    "    return result\n",
    "\n",
    "\n",
    "print(flatten([\"junk\", [\"nested stuff\"], [], [[]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-18T07:02:53.135Z"
    }
   },
   "outputs": [],
   "source": [
    "all_words = flatten(datas)\n",
    "sr_allwords = pd.Series(all_words)\n",
    "sr_allwords = sr_allwords.value_counts()\n",
    "set_words = sr_allwords.index\n",
    "set_ids = range(1, len(set_words)+1)    \n",
    "word2id = pd.Series(set_ids, index=set_words)\n",
    "id2word = pd.Series(set_words, index=set_ids)\n",
    "\n",
    "word2id[\"unknow\"] = len(word2id)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-18T07:02:53.353Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "def X_padding(words):\n",
    "    \"\"\"把 words 转为 id 形式，并自动补全位 max_len 长度。\"\"\"\n",
    "    ids = list(word2id[words])\n",
    "    if len(ids) >= max_len:  # 长则弃掉\n",
    "        return ids[:max_len]\n",
    "    ids.extend([0]*(max_len-len(ids))) # 短则补全\n",
    "    return ids\n",
    "\n",
    "def y_padding(ids):\n",
    "    \"\"\"把 tags 转为 id 形式， 并自动补全位 max_len 长度。\"\"\"\n",
    "    if len(ids) >= max_len:  # 长则弃掉\n",
    "        return ids[:max_len]\n",
    "    ids.extend([0]*(max_len-len(ids))) # 短则补全\n",
    "    return ids\n",
    "\n",
    "df_data = pd.DataFrame({'words': datas, 'tags': labels}, index=range(len(datas)))\n",
    "df_data['x'] = df_data['words'].apply(X_padding)\n",
    "df_data['y'] = df_data['tags'].apply(y_padding)\n",
    "x = np.asarray(list(df_data['x'].values))\n",
    "y = np.asarray(list(df_data['y'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-18T07:01:41.362Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=43)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train,  test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-18T07:01:44.593Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Finished creating the data generator.')\n",
    "import pickle\n",
    "import os\n",
    "with open('../dataMSRA.pkl', 'wb') as outp:\n",
    "\tpickle.dump(word2id, outp)\n",
    "\tpickle.dump(id2word, outp)\n",
    "\tpickle.dump(tag2id, outp)\n",
    "\tpickle.dump(id2tag, outp)\n",
    "\tpickle.dump(x_train, outp)\n",
    "\tpickle.dump(y_train, outp)\n",
    "\tpickle.dump(x_test, outp)\n",
    "\tpickle.dump(y_test, outp)\n",
    "\tpickle.dump(x_valid, outp)\n",
    "\tpickle.dump(y_valid, outp)\n",
    "print('** Finished saving the data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
